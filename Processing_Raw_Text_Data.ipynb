{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "878e6b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\jagad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\gutenberg.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jagad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg as cg\n",
    "from nltk.tokenize import sent_tokenize as st\n",
    "\n",
    "# Ensure required NLTK data is downloaded\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "735accaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read raw data from a file\n",
    "def fileread():\n",
    "    \"\"\"\n",
    "    Reads the content of a text file and returns it as a string.\n",
    "    Handles FileNotFoundError gracefully.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_path = \"C:/Users/jagad/Desktop/NLP/rawtextcorpus.txt\"\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            file_contents = file.read()\n",
    "        return file_contents\n",
    "    except FileNotFoundError:\n",
    "        return \"Error: File not found. Please ensure the file exists at the specified path.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a96230b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign local text data\n",
    "def localtextvalue():\n",
    "    \"\"\"\n",
    "    Returns a sample text string to analyze.\n",
    "    \"\"\"\n",
    "    text = \"\"\"One paragraph, of 100-250 words, which summarizes the purpose, methods, results and conclusions of the paper.\n",
    "    It is not easy to include all this information in just a few words. Start by writing a summary that includes whatever you think is important,\n",
    "    and then gradually prune it down to size by removing unnecessary words, while still retaining the necessary concepts.\n",
    "    Don't use abbreviations or citations in the abstract. It should be able to stand alone without any footnotes. Fig 1.1.1 shows below.\"\"\"\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "739bd09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to read data from an NLTK corpus\n",
    "def readcorpus():\n",
    "    \"\"\"\n",
    "    Returns the first 1000 characters of the 'burgess-busterbrown.txt' text from the NLTK Gutenberg corpus.\n",
    "    \"\"\"\n",
    "    raw_content_cg = cg.raw(\"burgess-busterbrown.txt\")\n",
    "    return raw_content_cg[0:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7c3798e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- Output from Raw Text File -----------\n",
      "\n",
      "one paragraph, of 100-250 words, which summarizes the purpose, methods, results and conclusions of the paper.\n",
      "It is not easy to include all this information in just a few words. Start by writing a summary that includes whatever you think is important,\n",
      "and then gradually prune it down to size by removing unnecessary words, while still retaining the necessary concepts. Don't use abbreviations or citations in the abstract. It should be able to stand alone without any footnotes. Fig 1.1.1 shows below.\"\"\"\n",
      "\n",
      "Number of sentences in raw text file: 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    # Output from Raw Text File\n",
    "    print(\"\\n---------- Output from Raw Text File -----------\\n\")\n",
    "    filecontentdetails = fileread()\n",
    "    print(filecontentdetails)\n",
    "\n",
    "    if not filecontentdetails.startswith(\"Error:\"):\n",
    "        st_list_rawfile = st(filecontentdetails)\n",
    "        print(f\"\\nNumber of sentences in raw text file: {len(st_list_rawfile)}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a6ecb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------- Output from Assigned Variable -------\n",
      "\n",
      "One paragraph, of 100-250 words, which summarizes the purpose, methods, results and conclusions of the paper.\n",
      "    It is not easy to include all this information in just a few words. Start by writing a summary that includes whatever you think is important,\n",
      "    and then gradually prune it down to size by removing unnecessary words, while still retaining the necessary concepts.\n",
      "    Don't use abbreviations or citations in the abstract. It should be able to stand alone without any footnotes. Fig 1.1.1 shows below.\n",
      "\n",
      "Number of sentences in assigned variable: 6\n",
      "Tokenized sentences: ['One paragraph, of 100-250 words, which summarizes the purpose, methods, results and conclusions of the paper.', 'It is not easy to include all this information in just a few words.', 'Start by writing a summary that includes whatever you think is important,\\n    and then gradually prune it down to size by removing unnecessary words, while still retaining the necessary concepts.', \"Don't use abbreviations or citations in the abstract.\", 'It should be able to stand alone without any footnotes.', 'Fig 1.1.1 shows below.']\n",
      "\n",
      "------- Output Corpus Data --------------\n",
      "\n",
      "[The Adventures of Buster Bear by Thornton W. Burgess 1920]\r\n",
      "\r\n",
      "I\r\n",
      "\r\n",
      "BUSTER BEAR GOES FISHING\r\n",
      "\r\n",
      "\r\n",
      "Buster Bear yawned as he lay on his comfortable bed of leaves and\r\n",
      "watched the first early morning sunbeams creeping through the Green\r\n",
      "Forest to chase out the Black Shadows. Once more he yawned, and slowly\r\n",
      "got to his feet and shook himself. Then he walked over to a big\r\n",
      "pine-tree, stood up on his hind legs, reached as high up on the trunk of\r\n",
      "the tree as he could, and scratched the bark with his great claws. After\r\n",
      "that he yawned until it seemed as if his jaws would crack, and then sat\r\n",
      "down to think what he wanted for breakfast.\r\n",
      "\r\n",
      "While he sat there, trying to make up his mind what would taste best, he\r\n",
      "was listening to the sounds that told of the waking of all the little\r\n",
      "people who live in the Green Forest. He heard Sammy Jay way off in the\r\n",
      "distance screaming, \"Thief! Thief!\" and grinned. \"I wonder,\" thought\r\n",
      "Buster, \"if some one has stolen Sammy's breakfast, or if he has stolen\r\n",
      "th\n",
      "\n",
      "Number of sentences in corpus data: 9\n",
      "Tokenized sentences: ['[The Adventures of Buster Bear by Thornton W. Burgess 1920]\\r\\n\\r\\nI\\r\\n\\r\\nBUSTER BEAR GOES FISHING\\r\\n\\r\\n\\r\\nBuster Bear yawned as he lay on his comfortable bed of leaves and\\r\\nwatched the first early morning sunbeams creeping through the Green\\r\\nForest to chase out the Black Shadows.', 'Once more he yawned, and slowly\\r\\ngot to his feet and shook himself.', 'Then he walked over to a big\\r\\npine-tree, stood up on his hind legs, reached as high up on the trunk of\\r\\nthe tree as he could, and scratched the bark with his great claws.', 'After\\r\\nthat he yawned until it seemed as if his jaws would crack, and then sat\\r\\ndown to think what he wanted for breakfast.', 'While he sat there, trying to make up his mind what would taste best, he\\r\\nwas listening to the sounds that told of the waking of all the little\\r\\npeople who live in the Green Forest.', 'He heard Sammy Jay way off in the\\r\\ndistance screaming, \"Thief!', 'Thief!\"', 'and grinned.', '\"I wonder,\" thought\\r\\nBuster, \"if some one has stolen Sammy\\'s breakfast, or if he has stolen\\r\\nth']\n"
     ]
    }
   ],
   "source": [
    "# Output from Assigned Variable\n",
    "print(\"\\n------- Output from Assigned Variable -------\\n\")\n",
    "localvariabledata = localtextvalue()\n",
    "print(localvariabledata)\n",
    "st_list_local = st(localvariabledata)\n",
    "print(f\"\\nNumber of sentences in assigned variable: {len(st_list_local)}\")\n",
    "print(f\"Tokenized sentences: {st_list_local}\")\n",
    "\n",
    "# Output from Corpus Data\n",
    "print(\"\\n------- Output Corpus Data --------------\\n\")\n",
    "fromcorpusdata = readcorpus()\n",
    "print(fromcorpusdata)\n",
    "st_list_corpus = st(fromcorpusdata)\n",
    "print(f\"\\nNumber of sentences in corpus data: {len(st_list_corpus)}\")\n",
    "print(f\"Tokenized sentences: {st_list_corpus}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9d0a47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
