{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c5a9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jagad\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ List of Stop Words -------\n",
      "i\n",
      "me\n",
      "my\n",
      "myself\n",
      "we\n",
      "our\n",
      "ours\n",
      "ourselves\n",
      "you\n",
      "you're\n",
      "you've\n",
      "you'll\n",
      "you'd\n",
      "your\n",
      "yours\n",
      "yourself\n",
      "yourselves\n",
      "he\n",
      "him\n",
      "his\n",
      "himself\n",
      "she\n",
      "she's\n",
      "her\n",
      "hers\n",
      "herself\n",
      "it\n",
      "it's\n",
      "its\n",
      "itself\n",
      "they\n",
      "them\n",
      "their\n",
      "theirs\n",
      "themselves\n",
      "what\n",
      "which\n",
      "who\n",
      "whom\n",
      "this\n",
      "that\n",
      "that'll\n",
      "these\n",
      "those\n",
      "am\n",
      "is\n",
      "are\n",
      "was\n",
      "were\n",
      "be\n",
      "been\n",
      "being\n",
      "have\n",
      "has\n",
      "had\n",
      "having\n",
      "do\n",
      "does\n",
      "did\n",
      "doing\n",
      "a\n",
      "an\n",
      "the\n",
      "and\n",
      "but\n",
      "if\n",
      "or\n",
      "because\n",
      "as\n",
      "until\n",
      "while\n",
      "of\n",
      "at\n",
      "by\n",
      "for\n",
      "with\n",
      "about\n",
      "against\n",
      "between\n",
      "into\n",
      "through\n",
      "during\n",
      "before\n",
      "after\n",
      "above\n",
      "below\n",
      "to\n",
      "from\n",
      "up\n",
      "down\n",
      "in\n",
      "out\n",
      "on\n",
      "off\n",
      "over\n",
      "under\n",
      "again\n",
      "further\n",
      "then\n",
      "once\n",
      "here\n",
      "there\n",
      "when\n",
      "where\n",
      "why\n",
      "how\n",
      "all\n",
      "any\n",
      "both\n",
      "each\n",
      "few\n",
      "more\n",
      "most\n",
      "other\n",
      "some\n",
      "such\n",
      "no\n",
      "nor\n",
      "not\n",
      "only\n",
      "own\n",
      "same\n",
      "so\n",
      "than\n",
      "too\n",
      "very\n",
      "s\n",
      "t\n",
      "can\n",
      "will\n",
      "just\n",
      "don\n",
      "don't\n",
      "should\n",
      "should've\n",
      "now\n",
      "d\n",
      "ll\n",
      "m\n",
      "o\n",
      "re\n",
      "ve\n",
      "y\n",
      "ain\n",
      "aren\n",
      "aren't\n",
      "couldn\n",
      "couldn't\n",
      "didn\n",
      "didn't\n",
      "doesn\n",
      "doesn't\n",
      "hadn\n",
      "hadn't\n",
      "hasn\n",
      "hasn't\n",
      "haven\n",
      "haven't\n",
      "isn\n",
      "isn't\n",
      "ma\n",
      "mightn\n",
      "mightn't\n",
      "mustn\n",
      "mustn't\n",
      "needn\n",
      "needn't\n",
      "shan\n",
      "shan't\n",
      "shouldn\n",
      "shouldn't\n",
      "wasn\n",
      "wasn't\n",
      "weren\n",
      "weren't\n",
      "won\n",
      "won't\n",
      "wouldn\n",
      "wouldn't\n",
      "\n",
      "-------- Customized Stopword Removal ---------\n",
      "Original Text: hi this is foo. bye\n",
      "Filtered Text: this is foo.\n",
      "\n",
      "-------- Stopword Removal from Raw Text ---------\n",
      "Original Text: This is a test sentence. I am very happy today.\n",
      "Filtered Text: test sentence. happy today.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Ensure required NLTK data is downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def stopwordlist():\n",
    "    \"\"\"\n",
    "    Displays the list of stopwords in the NLTK English corpus.\n",
    "    \"\"\"\n",
    "    stopwordlist = stopwords.words('english')\n",
    "    print(\"\\n------ List of Stop Words -------\")\n",
    "    for s in stopwordlist:\n",
    "        print(s)\n",
    "\n",
    "def customizedstopwordremove():\n",
    "    \"\"\"\n",
    "    Removes customized stopwords from a given line.\n",
    "    \"\"\"\n",
    "    stop_words = set([\"hi\", \"bye\"])\n",
    "    line = \"\"\"hi this is foo. bye\"\"\"\n",
    "    print(\"\\n-------- Customized Stopword Removal ---------\")\n",
    "    print(\"Original Text:\", line)\n",
    "    print(\"Filtered Text:\", \" \".join(word for word in line.split() if word not in stop_words))\n",
    "\n",
    "def stopwordremove():\n",
    "    \"\"\"\n",
    "    Removes NLTK stopwords from a sample sentence.\n",
    "    \"\"\"\n",
    "    stop = set(stopwords.words('english'))\n",
    "    sentence = \"This is a test sentence. I am very happy today.\"\n",
    "    print(\"\\n-------- Stopword Removal from Raw Text ---------\")\n",
    "    print(\"Original Text:\", sentence)\n",
    "    print(\"Filtered Text:\", \" \".join([i for i in sentence.lower().split() if i not in stop]))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    stopwordlist()\n",
    "    customizedstopwordremove()\n",
    "    stopwordremove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2777ae89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
