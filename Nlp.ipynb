{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFpxziWrkfpeMFPKy7Mk4s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isalut/couch-potato/blob/main/Nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xwk7ssoKuHhL"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('gutenberg')\n",
        "from nltk.corpus import gutenberg as cg\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DqRkr-JuNyJ",
        "outputId": "0e9850e7-5629-4f18-ed03-a450b451e64a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fileread():\n",
        "    filecontents=open(\"tulasi.txt\",\"r\").read()\n",
        "    return filecontents\n",
        "def localtextvalue():\n",
        "    text=\"#@Hello welcome to natural language processing 123 subject.Bapatla Engineering College,Bapatla\"\n",
        "    return text\n",
        "def readcorpus():\n",
        "    raw_content_cg=cg.raw(\"burgess-busterbrown.txt\")\n",
        "    return raw_content_cg[0:1000]\n",
        "if __name__==\"__main__\":\n",
        "    print(\"---text file output--\")\n",
        "    print(fileread())\n",
        "    print(\"--local variable output--\")\n",
        "    print(localtextvalue())\n",
        "    print(\"--corpus output--\")\n",
        "    print(readcorpus())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdiQ-5AXuYGo",
        "outputId": "163989cd-3540-48a0-967a-f85ca53ca568"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---text file output--\n",
            "\"Hello World! This is a simple NLP example.,Contact me at john.doe@example.com or visit https://www.example.com.\"\n",
            "--local variable output--\n",
            "#@Hello welcome to natural language processing 123 subject.Bapatla Engineering College,Bapatla\n",
            "--corpus output--\n",
            "[The Adventures of Buster Bear by Thornton W. Burgess 1920]\r\n",
            "\r\n",
            "I\r\n",
            "\r\n",
            "BUSTER BEAR GOES FISHING\r\n",
            "\r\n",
            "\r\n",
            "Buster Bear yawned as he lay on his comfortable bed of leaves and\r\n",
            "watched the first early morning sunbeams creeping through the Green\r\n",
            "Forest to chase out the Black Shadows. Once more he yawned, and slowly\r\n",
            "got to his feet and shook himself. Then he walked over to a big\r\n",
            "pine-tree, stood up on his hind legs, reached as high up on the trunk of\r\n",
            "the tree as he could, and scratched the bark with his great claws. After\r\n",
            "that he yawned until it seemed as if his jaws would crack, and then sat\r\n",
            "down to think what he wanted for breakfast.\r\n",
            "\r\n",
            "While he sat there, trying to make up his mind what would taste best, he\r\n",
            "was listening to the sounds that told of the waking of all the little\r\n",
            "people who live in the Green Forest. He heard Sammy Jay way off in the\r\n",
            "distance screaming, \"Thief! Thief!\" and grinned. \"I wonder,\" thought\r\n",
            "Buster, \"if some one has stolen Sammy's breakfast, or if he has stolen\r\n",
            "th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def wordlowercase():\n",
        "    local=localtextvalue().lower()\n",
        "    file=fileread().lower()\n",
        "    red1=readcorpus().lower()\n",
        "    return local,red1,file\n",
        "l,r,f=wordlowercase()\n",
        "print('--localtextvalue--')\n",
        "print(l)\n",
        "print('\\n--file--\\n')\n",
        "print(f)\n",
        "print()\n",
        "print('--readcorpus--\\n',r)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jYAClAfvPju",
        "outputId": "b8bc0399-5307-4189-a9ea-9a6c46985198"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--localtextvalue--\n",
            "#@hello welcome to natural language processing 123 subject.bapatla engineering college,bapatla\n",
            "\n",
            "--file--\n",
            "\n",
            "\"hello world! this is a simple nlp example.,contact me at john.doe@example.com or visit https://www.example.com.\"\n",
            "\n",
            "--readcorpus--\n",
            " [the adventures of buster bear by thornton w. burgess 1920]\r\n",
            "\r\n",
            "i\r\n",
            "\r\n",
            "buster bear goes fishing\r\n",
            "\r\n",
            "\r\n",
            "buster bear yawned as he lay on his comfortable bed of leaves and\r\n",
            "watched the first early morning sunbeams creeping through the green\r\n",
            "forest to chase out the black shadows. once more he yawned, and slowly\r\n",
            "got to his feet and shook himself. then he walked over to a big\r\n",
            "pine-tree, stood up on his hind legs, reached as high up on the trunk of\r\n",
            "the tree as he could, and scratched the bark with his great claws. after\r\n",
            "that he yawned until it seemed as if his jaws would crack, and then sat\r\n",
            "down to think what he wanted for breakfast.\r\n",
            "\r\n",
            "while he sat there, trying to make up his mind what would taste best, he\r\n",
            "was listening to the sounds that told of the waking of all the little\r\n",
            "people who live in the green forest. he heard sammy jay way off in the\r\n",
            "distance screaming, \"thief! thief!\" and grinned. \"i wonder,\" thought\r\n",
            "buster, \"if some one has stolen sammy's breakfast, or if he has stolen\r\n",
            "th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "def punctuation():\n",
        "    l,r,f=wordlowercase()\n",
        "    pl = l.translate(str.maketrans('', '', string.punctuation))\n",
        "    pf=f.translate(str.maketrans('', '', string.punctuation))\n",
        "    return pl,pf\n",
        "pl1,pf1=punctuation()\n",
        "print('local---\\n',pl1)\n",
        "print('file---\\n',pf1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgtlIRJd2Xc9",
        "outputId": "9adb6908-283d-4b29-ce55-0bce1a60fa54"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "local---\n",
            " hello welcome to natural language processing 123 subjectbapatla engineering collegebapatla\n",
            "file---\n",
            " hello world this is a simple nlp examplecontact me at johndoeexamplecom or visit httpswwwexamplecom\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def removeNum():\n",
        "  l,f=punctuation()\n",
        "  nl= re.sub(r'\\d+', '', l)\n",
        "  nf= re.sub(r'\\d+', '', f)\n",
        "  return nl,nf\n",
        "nl1,nf1=removeNum()\n",
        "print('local--\\n',nl1)\n",
        "print('file---\\n',nf1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCZdDoId2JhS",
        "outputId": "5130d2db-cc66-4286-b759-b6c64039b79e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "local--\n",
            " hello welcome to natural language processing  subjectbapatla engineering collegebapatla\n",
            "file---\n",
            " hello world this is a simple nlp examplecontact me at johndoeexamplecom or visit httpswwwexamplecom\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing Special Characters\n",
        "text = \"Hello World! #NLP @2024\"\n",
        "text_no_special_chars = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "print(text_no_special_chars)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2ls4Eu3z1M4",
        "outputId": "76f72044-8ca5-4889-b608-fffc47afbf0f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World NLP \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "# Ensure required NLTK data is downloaded\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def stopwordlist():\n",
        "    \"\"\"\n",
        "    Displays the list of stopwords in the NLTK English corpus.\n",
        "    \"\"\"\n",
        "    stopwordlist = stopwords.words('english')\n",
        "    print(\"\\n------ List of Stop Words -------\")\n",
        "    for s in stopwordlist:\n",
        "        print(s)\n",
        "\n",
        "def customizedstopwordremove():\n",
        "    \"\"\"\n",
        "    Removes customized stopwords from a given line.\n",
        "    \"\"\"\n",
        "    stop_words = set([\"hi\", \"bye\"])\n",
        "    line = \"\"\"hi this is foo. bye\"\"\"\n",
        "    print(\"\\n-------- Customized Stopword Removal ---------\")\n",
        "    print(\"Original Text:\", line)\n",
        "    print(\"Filtered Text:\", \" \".join(word for word in line.split() if word not in stop_words))\n",
        "\n",
        "def stopwordremove():\n",
        "    \"\"\"\n",
        "    Removes NLTK stopwords from a sample sentence.\n",
        "    \"\"\"\n",
        "    stop = set(stopwords.words('english'))\n",
        "    sentence = \"This is a test sentence. I am very happy today.\"\n",
        "    print(\"\\n-------- Stopword Removal from Raw Text ---------\")\n",
        "    print(\"Original Text:\", sentence)\n",
        "    print(\"Filtered Text:\", \" \".join([i for i in sentence.lower().split() if i not in stop]))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    stopwordlist()\n",
        "    customizedstopwordremove()\n",
        "    stopwordremove()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwPCpH_mvuv4",
        "outputId": "7d6ed5ff-eae3-45cb-cf86-0e2ac2dbaf52"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------ List of Stop Words -------\n",
            "i\n",
            "me\n",
            "my\n",
            "myself\n",
            "we\n",
            "our\n",
            "ours\n",
            "ourselves\n",
            "you\n",
            "you're\n",
            "you've\n",
            "you'll\n",
            "you'd\n",
            "your\n",
            "yours\n",
            "yourself\n",
            "yourselves\n",
            "he\n",
            "him\n",
            "his\n",
            "himself\n",
            "she\n",
            "she's\n",
            "her\n",
            "hers\n",
            "herself\n",
            "it\n",
            "it's\n",
            "its\n",
            "itself\n",
            "they\n",
            "them\n",
            "their\n",
            "theirs\n",
            "themselves\n",
            "what\n",
            "which\n",
            "who\n",
            "whom\n",
            "this\n",
            "that\n",
            "that'll\n",
            "these\n",
            "those\n",
            "am\n",
            "is\n",
            "are\n",
            "was\n",
            "were\n",
            "be\n",
            "been\n",
            "being\n",
            "have\n",
            "has\n",
            "had\n",
            "having\n",
            "do\n",
            "does\n",
            "did\n",
            "doing\n",
            "a\n",
            "an\n",
            "the\n",
            "and\n",
            "but\n",
            "if\n",
            "or\n",
            "because\n",
            "as\n",
            "until\n",
            "while\n",
            "of\n",
            "at\n",
            "by\n",
            "for\n",
            "with\n",
            "about\n",
            "against\n",
            "between\n",
            "into\n",
            "through\n",
            "during\n",
            "before\n",
            "after\n",
            "above\n",
            "below\n",
            "to\n",
            "from\n",
            "up\n",
            "down\n",
            "in\n",
            "out\n",
            "on\n",
            "off\n",
            "over\n",
            "under\n",
            "again\n",
            "further\n",
            "then\n",
            "once\n",
            "here\n",
            "there\n",
            "when\n",
            "where\n",
            "why\n",
            "how\n",
            "all\n",
            "any\n",
            "both\n",
            "each\n",
            "few\n",
            "more\n",
            "most\n",
            "other\n",
            "some\n",
            "such\n",
            "no\n",
            "nor\n",
            "not\n",
            "only\n",
            "own\n",
            "same\n",
            "so\n",
            "than\n",
            "too\n",
            "very\n",
            "s\n",
            "t\n",
            "can\n",
            "will\n",
            "just\n",
            "don\n",
            "don't\n",
            "should\n",
            "should've\n",
            "now\n",
            "d\n",
            "ll\n",
            "m\n",
            "o\n",
            "re\n",
            "ve\n",
            "y\n",
            "ain\n",
            "aren\n",
            "aren't\n",
            "couldn\n",
            "couldn't\n",
            "didn\n",
            "didn't\n",
            "doesn\n",
            "doesn't\n",
            "hadn\n",
            "hadn't\n",
            "hasn\n",
            "hasn't\n",
            "haven\n",
            "haven't\n",
            "isn\n",
            "isn't\n",
            "ma\n",
            "mightn\n",
            "mightn't\n",
            "mustn\n",
            "mustn't\n",
            "needn\n",
            "needn't\n",
            "shan\n",
            "shan't\n",
            "shouldn\n",
            "shouldn't\n",
            "wasn\n",
            "wasn't\n",
            "weren\n",
            "weren't\n",
            "won\n",
            "won't\n",
            "wouldn\n",
            "wouldn't\n",
            "\n",
            "-------- Customized Stopword Removal ---------\n",
            "Original Text: hi this is foo. bye\n",
            "Filtered Text: this is foo.\n",
            "\n",
            "-------- Stopword Removal from Raw Text ---------\n",
            "Original Text: This is a test sentence. I am very happy today.\n",
            "Filtered Text: test sentence. happy today.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing Extra Whitespaces\n",
        "text = \"Hello     World!   This   is    NLP.\"\n",
        "text_no_extra_spaces = ' '.join(text.split())\n",
        "print(text_no_extra_spaces)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ofsWDNg6PTw",
        "outputId": "3f47b823-a4da-4cd2-8dbd-70b15180dca0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World! This is NLP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Regex\n",
        "import re\n",
        "\n",
        "# Sample text containing Indian phone numbers, emails, and URLs\n",
        "text = \"\"\"\n",
        "Contact me at +91 8096696726 or 9573471012.\n",
        "You can also reach me at tulasi.doe@example.com or bala123@example.net.\n",
        "Check out our website at https://www.example.com for more info.\n",
        "Alternatively, visit http://example.org.\n",
        "My other number is +91 8096696726 or 9573471012.\n",
        "Another number: 919876543210.\n",
        "\"\"\"\n",
        "\n",
        "# Define regex patterns\n",
        "phone_pattern = re.compile(r'(?:\\+91|91)?[-.\\s]?[6789]\\d{9}')\n",
        "email_pattern = re.compile(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}')\n",
        "url_pattern = re.compile(r'https?://[^\\s]+')\n",
        "\n",
        "# Extract  phone numbers\n",
        "phone_numbers = phone_pattern.findall(text)\n",
        "print(\"Phone Numbers:\", phone_numbers)\n",
        "\n",
        "# Extract email addresses\n",
        "email_addresses = email_pattern.findall(text)\n",
        "print(\"Email Addresses:\", email_addresses)\n",
        "\n",
        "# Extract URLs\n",
        "urls = url_pattern.findall(text)\n",
        "print(\"URLs:\", urls)\n",
        "\n",
        "# Mask Indian phone numbers\n",
        "masked_text = phone_pattern.sub('[PHONE NUMBER]', text)\n",
        "\n",
        "# Mask email addresses\n",
        "masked_text = email_pattern.sub('[EMAIL ADDRESS]', masked_text)\n",
        "\n",
        "# Print masked text\n",
        "print(\"\\nMasked Text:\\n\", masked_text)\n",
        "\n",
        "# Split text into sentences\n",
        "sentence_pattern = re.compile(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s')\n",
        "sentences = sentence_pattern.split(text)\n",
        "print(\"\\nSentences:\", sentences)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUUOUMo666Du",
        "outputId": "2253add5-05d1-469f-95d3-427afc8e2a61"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phone Numbers: ['+91 8096696726', ' 9573471012', '+91 8096696726', ' 9573471012', ' 9198765432']\n",
            "Email Addresses: ['tulasi.doe@example.com', 'bala123@example.net']\n",
            "URLs: ['https://www.example.com', 'http://example.org.']\n",
            "\n",
            "Masked Text:\n",
            " \n",
            "Contact me at [PHONE NUMBER] or[PHONE NUMBER].\n",
            "You can also reach me at [EMAIL ADDRESS] or [EMAIL ADDRESS].\n",
            "Check out our website at https://www.example.com for more info.\n",
            "Alternatively, visit http://example.org.\n",
            "My other number is [PHONE NUMBER] or[PHONE NUMBER].\n",
            "Another number:[PHONE NUMBER]10.\n",
            "\n",
            "\n",
            "Sentences: ['\\nContact me at +91 8096696726 or 9573471012.', 'You can also reach me at tulasi.doe@example.com or bala123@example.net.', 'Check out our website at https://www.example.com for more info.', 'Alternatively, visit http://example.org.', 'My other number is +91 8096696726 or 9573471012.', 'Another number: 919876543210.', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W8uFpAuS7EcB"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fl3mcCmb7H41"
      },
      "execution_count": 57,
      "outputs": []
    }
  ]
}