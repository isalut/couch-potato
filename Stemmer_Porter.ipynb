{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca4e3a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd38c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jagad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\jagad\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure required NLTK data is downloaded\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dedab4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text\n",
    "text = \"\"\"Stemming is funnier than a bummer says the sushi loving computer scientist.\n",
    "She really wants to buy cars. She told me angrily.\n",
    "It is better for you. Man is walking. We are meeting tomorrow.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfabfd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer_porter():\n",
    "    \"\"\"\n",
    "    Applies stemming to the text using the Porter Stemmer.\n",
    "    \"\"\"\n",
    "    port = PorterStemmer()\n",
    "    print(\"\\nStemmer:\")\n",
    "    return \" \".join([port.stem(i) for i in text.split()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb50cc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stemmer:\n",
      "stem is funnier than a bummer say the sushi love comput scientist. she realli want to buy cars. she told me angrily. it is better for you. man is walking. we are meet tomorrow.\n",
      "\n",
      "Verb Lemma:\n",
      "Stemming be funnier than a bummer say the sushi love computer scientist. She really want to buy cars. She tell me angrily. It be better for you. Man be walking. We be meet tomorrow.\n",
      "\n",
      "Noun Lemma:\n",
      "Stemming is funnier than a bummer say the sushi loving computer scientist. She really want to buy cars. She told me angrily. It is better for you. Man is walking. We are meeting tomorrow.\n",
      "\n",
      "Adjective Lemma:\n",
      "Stemming is funny than a bummer says the sushi loving computer scientist. She really wants to buy cars. She told me angrily. It is good for you. Man is walking. We are meeting tomorrow.\n",
      "\n",
      "Satellite Adjectives Lemma:\n",
      "Stemming is funny than a bummer says the sushi loving computer scientist. She really wants to buy cars. She told me angrily. It is good for you. Man is walking. We are meeting tomorrow.\n",
      "\n",
      "Adverb Lemma:\n",
      "Stemming is funnier than a bummer says the sushi loving computer scientist. She really wants to buy cars. She told me angrily. It is well for you. Man is walking. We are meeting tomorrow.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def lemmatizer():\n",
    "    \"\"\"\n",
    "    Applies lemmatization to the text for various parts of speech (POS).\n",
    "    \"\"\"\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    ADJ, ADJ_SAT, ADV, NOUN, VERB = 'a', 's', 'r', 'n', 'v'\n",
    "    \n",
    "    # Verb Lemma\n",
    "    print(\"\\nVerb Lemma:\")\n",
    "    print(\" \".join([wordnet_lemmatizer.lemmatize(i, pos=VERB) for i in text.split()]))\n",
    "    \n",
    "    # Noun Lemma\n",
    "    print(\"\\nNoun Lemma:\")\n",
    "    print(\" \".join([wordnet_lemmatizer.lemmatize(i, pos=NOUN) for i in text.split()]))\n",
    "    \n",
    "    # Adjective Lemma\n",
    "    print(\"\\nAdjective Lemma:\")\n",
    "    print(\" \".join([wordnet_lemmatizer.lemmatize(i, pos=ADJ) for i in text.split()]))\n",
    "    \n",
    "    # Satellite Adjectives Lemma\n",
    "    print(\"\\nSatellite Adjectives Lemma:\")\n",
    "    print(\" \".join([wordnet_lemmatizer.lemmatize(i, pos=ADJ_SAT) for i in text.split()]))\n",
    "    \n",
    "    # Adverb Lemma\n",
    "    print(\"\\nAdverb Lemma:\")\n",
    "    print(\" \".join([wordnet_lemmatizer.lemmatize(i, pos=ADV) for i in text.split()]))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Stemming Output\n",
    "    print(stemmer_porter())\n",
    "    \n",
    "    # Lemmatization Output\n",
    "    lemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d929922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
